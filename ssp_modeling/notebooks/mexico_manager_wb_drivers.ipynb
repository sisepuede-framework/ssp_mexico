{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29eb0a-00ee-494d-9b3d-25da412bf1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import importlib  # needed so that we can reload packages\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from typing import Union, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.logger_utils import setup_clean_logger, mute_external_loggers\n",
    "\n",
    "# SISEPUEDE imports\n",
    "from sisepuede.manager.sisepuede_examples import SISEPUEDEExamples\n",
    "from sisepuede.manager.sisepuede_file_structure import SISEPUEDEFileStructure\n",
    "import sisepuede.core.support_classes as sc\n",
    "import sisepuede.transformers as trf\n",
    "import sisepuede.utilities._plotting as spu\n",
    "import sisepuede.utilities._toolbox as sf\n",
    "import sisepuede.core.attribute_table as att\n",
    "import sisepuede.manager.sisepuede_examples as sxl\n",
    "import sisepuede.manager.sisepuede_file_structure as sfs\n",
    "import sisepuede.manager.sisepuede_models as sm\n",
    "import sisepuede.visualization.plots as svp\n",
    "\n",
    "# --- Runtime configuration ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up a clean logger for your notebook\n",
    "logger = setup_clean_logger(\"notebook\", logging.INFO)\n",
    "logger.info(\"Notebook started successfully.\")\n",
    "\n",
    "# Mute logs from sisepuede to avoid duplication\n",
    "mute_external_loggers([\"sisepuede\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0483f2b",
   "metadata": {},
   "source": [
    "### Initial Set up\n",
    "\n",
    "Make sure to edit the config yaml under ssp_modeling/config_files/config.yaml\n",
    "\n",
    "You can also create a new config yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebcd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dir paths\n",
    "\n",
    "CURR_DIR_PATH = pathlib.Path(os.getcwd())\n",
    "SSP_MODELING_DIR_PATH = CURR_DIR_PATH.parent\n",
    "PROJECT_DIR_PATH = SSP_MODELING_DIR_PATH.parent\n",
    "DATA_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"input_data\")\n",
    "RUN_OUTPUT_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"ssp_run_output\")\n",
    "SCENARIO_MAPPING_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"scenario_mapping\")\n",
    "CONFIG_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"config_files\")\n",
    "TRANSFORMATIONS_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"transformations\")\n",
    "MISC_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"misc\")\n",
    "STRATEGIES_DEFINITIONS_FILE_PATH = TRANSFORMATIONS_DIR_PATH.joinpath(\"strategy_definitions.csv\")\n",
    "STRATEGY_MAPPING_FILE_PATH = MISC_DIR_PATH.joinpath(\"strategy_mapping.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac941c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssp_transformations_handler.GeneralUtils import GeneralUtils\n",
    "from ssp_transformations_handler.TransformationUtils import TransformationYamlProcessor, StrategyCSVHandler\n",
    "\n",
    "# Initialize general utilities\n",
    "g_utils = GeneralUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53908ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file, double check your parameters are correct\n",
    "\n",
    "YAML_FILE_PATH = os.path.join(CONFIG_DIR_PATH, \"config.yaml\")\n",
    "config_params = g_utils.read_yaml(YAML_FILE_PATH)\n",
    "\n",
    "country_name = config_params['country_name']\n",
    "ssp_input_file_name = config_params['ssp_input_file_name']\n",
    "ssp_transformation_cw = config_params['ssp_transformation_cw']\n",
    "energy_model_flag = config_params['energy_model_flag']\n",
    "set_lndu_reallocation_factor_to_zero_flag = config_params['set_lndu_reallocation_factor_to_zero']\n",
    "\n",
    "# Print config parameters\n",
    "logger.info(f\"Country name: {country_name}\")\n",
    "logger.info(f\"SSP input file name: {ssp_input_file_name}\")\n",
    "logger.info(f\"SSP transformation CW: {ssp_transformation_cw}\")\n",
    "logger.info(f\"Energy model flag: {energy_model_flag}\")\n",
    "logger.info(f\"Set lndu reallocation factor to zero flag: {set_lndu_reallocation_factor_to_zero_flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_structure(\n",
    "    y0: int = 2015,\n",
    "    y1: int = 2060,\n",
    ") -> Tuple[sfs.SISEPUEDEFileStructure, att.AttributeTable]:\n",
    "    \"\"\"Get the SISEPUEDE File Structure and update the attribute table\n",
    "        with new years.\n",
    "    \"\"\"\n",
    "    # setup some SISEPUEDE variables and update time period\n",
    "    file_struct = sfs.SISEPUEDEFileStructure(\n",
    "        initialize_directories = False,\n",
    "    )\n",
    " \n",
    "    # get some keys\n",
    "    key_time_period = file_struct.model_attributes.dim_time_period\n",
    "    key_year = file_struct.model_attributes.field_dim_year\n",
    " \n",
    " \n",
    "    ##  BUILD THE ATTRIBUTE AND UPDATE\n",
    " \n",
    "    # setup the new attribute table\n",
    "    years = np.arange(y0, y1 + 1, ).astype(int)\n",
    "    attribute_time_period = att.AttributeTable(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                key_time_period: range(len(years)),\n",
    "                key_year: years,\n",
    "            }\n",
    "        ),\n",
    "        key_time_period,\n",
    "    )\n",
    " \n",
    "    # finally, update the ModelAttributes inside the file structure\n",
    "    (\n",
    "        file_struct\n",
    "        .model_attributes\n",
    "        .update_dimensional_attribute_table(\n",
    "            attribute_time_period,\n",
    "        )\n",
    "    )\n",
    " \n",
    "    # return the tuple\n",
    "    out = (file_struct, attribute_time_period, )\n",
    " \n",
    "    return out\n",
    " \n",
    "# # setup models\n",
    "# models = sm.SISEPUEDEModels(\n",
    "#     matt,\n",
    "#     allow_electricity_run = True,\n",
    "#     fp_julia = _FILE_STRUCTURE.dir_jl,\n",
    "#     fp_nemomod_reference_files = _FILE_STRUCTURE.dir_ref_nemo,\n",
    "#     initialize_julia = True, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6c558-ba2c-482b-8743-7c46bfb64924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SSP objects\n",
    "INPUT_FILE_PATH = DATA_DIR_PATH.joinpath(ssp_input_file_name)\n",
    "\n",
    "# model attributes and associated support classes\n",
    "_EXAMPLES = sxl.SISEPUEDEExamples()\n",
    "_FILE_STRUCTURE, _ATTRIBUTE_TABLE_TIME_PERIOD = get_file_structure()\n",
    "matt = _FILE_STRUCTURE.model_attributes\n",
    "regions = sc.Regions(matt, )\n",
    "time_periods = sc.TimePeriods(matt, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f64c6a",
   "metadata": {},
   "source": [
    "### Making sure our input file has the correct format and correct columns\n",
    "We use an example df with the complete fields and correct format to make sure our file is in the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1e26f-7946-4f4f-a3b1-ff398c9fe211",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  BUILD BASE INPUTS\n",
    "df_inputs_raw = pd.read_csv(INPUT_FILE_PATH)\n",
    "\n",
    "# pull example data to fill in gaps\n",
    "df_example_input = _EXAMPLES(\"input_data_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking that our df is in the correct shape (Empty sets should be printed to make sure everything is Ok!)\n",
    "g_utils.compare_dfs(df_example_input, df_inputs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b012cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure if time_period field exist\n",
    "if 'time_period' not in df_inputs_raw.columns:\n",
    "    logger.info(\"Adding 'time_period' column to df_inputs_raw\")\n",
    "    df_inputs_raw = df_inputs_raw.rename(columns={'period':'time_period'})\n",
    "else:\n",
    "    logger.info(\"'time_period' column already exists in df_inputs_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes differences and makes sure that our df is in the correct format.\n",
    "# Note: Edit this if you need more changes in your df\n",
    "\n",
    "df_inputs_raw_complete = g_utils.add_missing_cols(df_example_input, df_inputs_raw.copy())\n",
    "df_inputs_raw_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking that our df is in the correct shape (Empty sets should be printed to make sure everything is Ok!)\n",
    "g_utils.compare_dfs(df_example_input, df_inputs_raw_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c11c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check region field\n",
    "df_inputs_raw_complete['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region to country name\n",
    "df_inputs_raw_complete['region'] = country_name\n",
    "df_inputs_raw_complete['region'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_yield_factor = matt.get_variable(\"Crop Yield Factor\")\n",
    "crop_yield_factor.get_from_dataframe(df_inputs_raw_complete).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['yf_agrc_cereals_tonne_ha'] *= 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['yf_agrc_sugar_cane_tonne_ha'] *= 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080eb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cropland_area_proportion = matt.get_variable(\"Initial Cropland Area Proportion\")\n",
    "initial_cropland_area_proportion.get_from_dataframe(df_inputs_raw_complete).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_demand_income_elasticity = matt.get_variable(\"Crop Demand Income Elasticity\")\n",
    "crop_demand_income_elasticity.get_from_dataframe(df_inputs_raw_complete).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cropland_area_proportion = matt.get_variable(\"Initial Land Use Area Proportion\")\n",
    "initial_cropland_area_proportion.get_from_dataframe(df_inputs_raw_complete).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of land use fraction columns in the SISEPUEDE input\n",
    "landuse_cols = [\n",
    "    \"frac_lndu_initial_croplands\",\n",
    "    \"frac_lndu_initial_flooded\",\n",
    "    \"frac_lndu_initial_forests_mangroves\",\n",
    "    \"frac_lndu_initial_forests_primary\",\n",
    "    \"frac_lndu_initial_forests_secondary\",\n",
    "    \"frac_lndu_initial_grasslands\",\n",
    "    \"frac_lndu_initial_other\",\n",
    "    \"frac_lndu_initial_pastures\",\n",
    "    \"frac_lndu_initial_settlements\",\n",
    "    \"frac_lndu_initial_shrublands\",\n",
    "    \"frac_lndu_initial_wetlands\"\n",
    "]\n",
    "\n",
    "df_inputs_raw_complete.loc[:, \"frac_lndu_initial_forests_primary\"] = 0.11   # ~11%\n",
    "df_inputs_raw_complete.loc[:, \"frac_lndu_initial_settlements\"]    = 0.013  # ~1.3%\n",
    "df_inputs_raw_complete.loc[:, \"frac_lndu_initial_shrublands\"]     = 0.29   # ~29%\n",
    "\n",
    "\n",
    "# Compute the row-wise sum of all land use fractions\n",
    "row_sum = df_inputs_raw_complete[landuse_cols].sum(axis=1)\n",
    "\n",
    "# Avoid division by zero just in case (should not happen, but safe)\n",
    "row_sum = row_sum.replace(0, pd.NA)\n",
    "\n",
    "# Divide each land use column by the row-wise sum\n",
    "df_inputs_raw_complete[landuse_cols] = (\n",
    "    df_inputs_raw_complete[landuse_cols].div(row_sum, axis=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cropland_area_proportion.get_from_dataframe(df_inputs_raw_complete).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d34fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de prefijos de productos industriales\n",
    "product_prefixes = [\n",
    "    \"frac_inen_energy_agriculture_and_livestock_\",\n",
    "    \"frac_inen_energy_cement_\",\n",
    "    \"frac_inen_energy_chemicals_\",\n",
    "    \"frac_inen_energy_electronics_\",\n",
    "    \"frac_inen_energy_glass_\",\n",
    "    \"frac_inen_energy_lime_and_carbonite_\",\n",
    "    \"frac_inen_energy_metals_\",\n",
    "    \"frac_inen_energy_mining_\",\n",
    "    \"frac_inen_energy_other_product_manufacturing_\",\n",
    "    \"frac_inen_energy_paper_\",\n",
    "    \"frac_inen_energy_plastic_\",\n",
    "    \"frac_inen_energy_recycled_glass_\",\n",
    "    \"frac_inen_energy_recycled_metals_\",\n",
    "    \"frac_inen_energy_recycled_paper_\",\n",
    "    \"frac_inen_energy_recycled_plastic_\",\n",
    "    \"frac_inen_energy_recycled_rubber_and_leather_\",\n",
    "    \"frac_inen_energy_recycled_textiles_\",\n",
    "    \"frac_inen_energy_recycled_wood_\",\n",
    "    \"frac_inen_energy_rubber_and_leather_\",\n",
    "    \"frac_inen_energy_textiles_\",\n",
    "    \"frac_inen_energy_wood_\"\n",
    "]\n",
    "\n",
    "# Targets para TODOS los productos\n",
    "targets = {\n",
    "    \"electricity\": 0.48,\n",
    "    \"natural_gas\": 0.27,\n",
    "    \"oil\": 0.17\n",
    "}\n",
    "\n",
    "# Iterar sobre cada prefijo / producto\n",
    "for prefix in product_prefixes:\n",
    "\n",
    "    # Identificar las columnas de ese producto\n",
    "    cols = [c for c in df_inputs_raw_complete.columns if c.startswith(prefix)]\n",
    "    if len(cols) == 0:\n",
    "        continue  # si no hay columnas, pasar al siguiente producto\n",
    "\n",
    "    # Columnas especÃ­ficas que deben fijarse\n",
    "    target_cols = {\n",
    "        prefix + \"electricity\": targets[\"electricity\"],\n",
    "        prefix + \"natural_gas\": targets[\"natural_gas\"],\n",
    "        prefix + \"oil\": targets[\"oil\"]\n",
    "    }\n",
    "\n",
    "    # Aplicar valores fijos a TODAS las filas\n",
    "    for col, val in target_cols.items():\n",
    "        if col in df_inputs_raw_complete.columns:\n",
    "            df_inputs_raw_complete.loc[:, col] = val\n",
    "\n",
    "    # Reescalar el resto para que sumen 1\n",
    "    for i in df_inputs_raw_complete.index:\n",
    "\n",
    "        row = df_inputs_raw_complete.loc[i, cols]\n",
    "\n",
    "        fixed_sum = sum(val for key, val in target_cols.items() if key in row.index)\n",
    "\n",
    "        remaining = 1 - fixed_sum\n",
    "\n",
    "        other_cols = [c for c in cols if c not in target_cols]\n",
    "        orig_sum_other = row[other_cols].sum()\n",
    "\n",
    "        if orig_sum_other > 0:\n",
    "            df_inputs_raw_complete.loc[i, other_cols] = (\n",
    "                row[other_cols] / orig_sum_other * remaining\n",
    "            )\n",
    "        else:\n",
    "            df_inputs_raw_complete.loc[i, other_cols] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_coal = matt.get_variable(\"Industrial Energy Fuel Fraction Coal\")\n",
    "industrial_energy_fraction_coal.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_coke = matt.get_variable(\"Industrial Energy Fuel Fraction Coke\")\n",
    "industrial_energy_fraction_coke.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531af953",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_diesel = matt.get_variable(\"Industrial Energy Fuel Fraction Diesel\")\n",
    "industrial_energy_fraction_diesel.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_electricity = matt.get_variable(\"Industrial Energy Fuel Fraction Electricity\")\n",
    "industrial_energy_fraction_electricity.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0db7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_electricity.get_from_dataframe(df_inputs_raw_complete).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed31cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_electricity.get_from_dataframe(df_inputs_raw_complete).iloc[7].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623acd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_furnace_gas = matt.get_variable(\"Industrial Energy Fuel Fraction Furnace Gas\")\n",
    "industrial_energy_fraction_furnace_gas.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_furnace_gasoline = matt.get_variable(\"Industrial Energy Fuel Fraction Gasoline\")\n",
    "industrial_energy_fraction_furnace_gasoline.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_geothermal = matt.get_variable(\"Industrial Energy Fuel Fraction Geothermal\")\n",
    "industrial_energy_fraction_geothermal.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d97f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_hydrocarbon_gas_liquids = matt.get_variable(\"Industrial Energy Fuel Fraction Hydrocarbon Gas Liquids\")\n",
    "industrial_energy_fraction_hydrocarbon_gas_liquids.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be282f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_hydrogen = matt.get_variable(\"Industrial Energy Fuel Fraction Hydrogen\")\n",
    "industrial_energy_fraction_hydrogen.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_kerosene = matt.get_variable(\"Industrial Energy Fuel Fraction Kerosene\")\n",
    "industrial_energy_fraction_kerosene.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63460191",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_natural_gas = matt.get_variable(\"Industrial Energy Fuel Fraction Natural Gas\")\n",
    "industrial_energy_fraction_natural_gas.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e49611",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_natural_gas = matt.get_variable(\"Industrial Energy Fuel Fraction Natural Gas\")\n",
    "industrial_energy_fraction_natural_gas.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_natural_gas.get_from_dataframe(df_inputs_raw_complete).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_natural_gas.get_from_dataframe(df_inputs_raw_complete).iloc[7].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_oil = matt.get_variable(\"Industrial Energy Fuel Fraction Oil\")\n",
    "industrial_energy_fraction_oil.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed442735",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_oil.get_from_dataframe(df_inputs_raw_complete).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71172e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial_energy_fraction_biomass = matt.get_variable(\"Industrial Energy Fuel Fraction Solid Biomass\")\n",
    "industrial_energy_fraction_biomass.get_from_dataframe(df_inputs_raw_complete).iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a76bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae925a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e4f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981cff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86101a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df_inputs_raw_complete.columns if c.startswith(\"yf_agrc_\")]\n",
    "df_inputs_raw_complete[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df_inputs_raw_complete.columns if c.startswith(\"prodinit_ippu_\")]\n",
    "df_inputs_raw_complete[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ab770",
   "metadata": {},
   "source": [
    "USGS â€“ Mineral Commodity Summary (Cement, 2021) â†’ MÃ©xico â‰ˆ 35 Mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['prodinit_ippu_cement_tonne'] *= 0.755"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bd643",
   "metadata": {},
   "source": [
    "More rasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['prodinit_ippu_electronics_tonne'] *= 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56265f",
   "metadata": {},
   "source": [
    "Low production of glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['prodinit_ippu_glass_tonne'] *= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb556470",
   "metadata": {},
   "source": [
    "lime and carbonite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['prodinit_ippu_lime_and_carbonite_tonne'] *= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792ce58",
   "metadata": {},
   "source": [
    "ðŸŽ¯ ProducciÃ³n minera total estimada para MÃ©xico 2020\n",
    "\n",
    "Sumando solo los grandes rubros:\n",
    "\tâ€¢\tCaliza: ~180 Mt\n",
    "\n",
    "\tâ€¢\tArena + grava: ~130 Mt\n",
    "\n",
    "\tâ€¢\tYeso + otros no metÃ¡licos: ~15 Mt\n",
    "\n",
    "\tâ€¢\tMinerales metÃ¡licos varios: ~20 Mt\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['prodinit_ippu_mining_tonne'] *= 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc676f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['consumpinit_scoe_tj_per_mmmgdp_commercial_municipal_elec_appliances'] *= 0.3\n",
    "\n",
    "df_inputs_raw_complete['consumpinit_scoe_tj_per_mmmgdp_commercial_municipal_heat_energy'] *= 0.3\n",
    "\n",
    "df_inputs_raw_complete['consumpinit_scoe_gj_per_hh_residential_heat_energy'] *= 0.3\n",
    "\n",
    "df_inputs_raw_complete['consumpinit_scoe_gj_per_hh_residential_elec_appliances'] *= 0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df_inputs_raw_complete.columns if c.startswith(\"prodinit_ippu_\")]\n",
    "df_inputs_raw_complete[cols].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f14871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['elasticity_ippu_rubber_and_leather_production_to_gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23741e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['elasticity_ippu_metals_production_to_gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e145bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['elasticity_ippu_metals_production_to_gdp'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['elasticity_ippu_rubber_and_leather_production_to_gdp'] = 1.0\n",
    "df_inputs_raw_complete['elasticity_ippu_rubber_and_leather_production_to_gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80514978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['elasticity_ippu_cement_production_to_gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac076f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete['elasticity_ippu_cement_production_to_gdp'] = 1.0\n",
    "df_inputs_raw_complete['elasticity_ippu_cement_production_to_gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26998af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete.to_csv(DATA_DIR_PATH.joinpath(\"sisepuede_raw_inputs_MEX_251209.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b179e3",
   "metadata": {},
   "source": [
    "## Let's Modify the  LNDU Reallocation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d97b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_lndu_reallocation_factor_to_zero_flag:\n",
    "    df_inputs_raw_complete['lndu_reallocation_factor'] = 0\n",
    "\n",
    "df_inputs_raw_complete['lndu_reallocation_factor'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw_complete = df_inputs_raw_complete[df_inputs_raw_complete['time_period'].between(0, 35)]\n",
    "df_inputs_raw_complete['time_period'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91491c34-78de-4bf9-bed3-3d69613bace7",
   "metadata": {},
   "source": [
    "#  Let's try building transformations using this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21339f-7e93-4123-aa07-8a12f0316756",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = trf.transformers.Transformers(\n",
    "    {},\n",
    "    attr_time_period = _ATTRIBUTE_TABLE_TIME_PERIOD,\n",
    "    df_input = df_inputs_raw_complete,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93521f1-0fa0-4f09-9b6e-def5662df3d8",
   "metadata": {},
   "source": [
    "##  Instantiate some transformations. Make sure to run this cell to create the transformations folder for the first time or if you wish to overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85aa9b2-412c-44f7-b75f-3bc486202843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an ouput path and instantiate\n",
    "if not TRANSFORMATIONS_DIR_PATH.exists():\n",
    "    trf.instantiate_default_strategy_directory(\n",
    "        transformers,\n",
    "        TRANSFORMATIONS_DIR_PATH,\n",
    "    )\n",
    "else:\n",
    "    logger.info(f\"Directory {TRANSFORMATIONS_DIR_PATH} already exists. Skipping instantiation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14522780-2f45-4402-8889-365f1d319303",
   "metadata": {},
   "source": [
    "##  --HERE, CUSTOMIZE YOUR TRANSFORMATIONS AND STRATEGIES--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03361640",
   "metadata": {},
   "source": [
    "### Customizing transformations and strategies files using TransformationUtils.py classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new transformation files based on the excel mapping file. \n",
    "# Make sure to have the most updated format for the excel file, check the one used in this notebook for reference.\n",
    "\n",
    "if ssp_transformation_cw is None:\n",
    "    logger.warning(\"ssp_transformation_cw is not defined. Please check your config file.\")\n",
    "else:\n",
    "    logger.info(f\"Using transformation file: {ssp_transformation_cw}\")\n",
    "    cw_file_path = os.path.join(SCENARIO_MAPPING_DIR_PATH, ssp_transformation_cw)\n",
    "    logger.info(f\"Transformation file path: {cw_file_path}\")\n",
    "    excel_yaml_handler = TransformationYamlProcessor(scenario_mapping_excel_path=cw_file_path, yaml_dir_path=TRANSFORMATIONS_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates transformation yaml files for each strategy in the excel file\n",
    "if ssp_transformation_cw is not None:\n",
    "    logger.info(\"Processing YAML files...\")\n",
    "    excel_yaml_handler.process_yaml_files()\n",
    "else:\n",
    "    logger.warning(\"ssp_transformation_cw is not defined. Please check your config file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformations per strategy dictionary so we can pass it to the strategy handler\n",
    "# You can also check here if the transformations in each strategy are correct\n",
    "\n",
    "if ssp_transformation_cw is not None:\n",
    "    logger.info(\"Loading transformations per strategy dictionary...\")\n",
    "    transformation_per_strategy_dict = excel_yaml_handler.get_transformations_per_strategy_dict()\n",
    "    transformation_per_strategy_dict\n",
    "    logger.info(f\"Loaded transformations for strategies: {transformation_per_strategy_dict.keys()}\")\n",
    "else:\n",
    "    logger.warning(\"No transformation handler available. Please check your config file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can explore the dictionary to see the transformations per strategy\n",
    "# transformation_per_strategy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb689de1",
   "metadata": {},
   "source": [
    "### Creating new strategies\n",
    "- You can create new strategies from scratch.\n",
    "- You can also update existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea277ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new strategies by updating the strategy_definitions file.\n",
    "\n",
    "if ssp_transformation_cw is not None:\n",
    "    # You can edit this to add yours, as many as you want.\n",
    "    csv_handler = StrategyCSVHandler(csv_file_path=STRATEGIES_DEFINITIONS_FILE_PATH, \n",
    "                                     yaml_dir_path=TRANSFORMATIONS_DIR_PATH, \n",
    "                                     yaml_mapping_file=STRATEGY_MAPPING_FILE_PATH, \n",
    "                                     transformation_per_strategy_dict=transformation_per_strategy_dict)\n",
    "\n",
    "    csv_handler.add_strategy(strategy_group='PFLO', description='NDC', yaml_file_suffix='NDC')\n",
    "    csv_handler.add_strategy(strategy_group='PFLO', description='NDC + Energy', yaml_file_suffix='NDC2')\n",
    "    csv_handler.add_strategy(strategy_group='PFLO', description='Net Zero', yaml_file_suffix='NZ')\n",
    "else:\n",
    "    logger.warning(\"No transformation handler available. Please check your config file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c7b74",
   "metadata": {},
   "source": [
    "### We finished adding new transformation files and strategies so lets load them back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd1a2f-4f3e-4c78-b9a6-b00446ee44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, you can load this back in after modifying (play around with it)\n",
    "transformations = trf.Transformations(\n",
    "    TRANSFORMATIONS_DIR_PATH,\n",
    "    transformers = transformers,\n",
    ")\n",
    "tab = transformations.attribute_transformation.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cd07a-feb1-4b4c-a755-43d0f639e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  build the strategies -- will export to path\n",
    "t0 = time.time()\n",
    "strategies = trf.Strategies(\n",
    "    transformations,\n",
    "    export_path = \"transformations\",\n",
    "    prebuild = True,\n",
    ")\n",
    "\n",
    "t_elapse = sf.get_time_elapsed(t0)\n",
    "logger.info(f\"Strategies defined at {strategies.transformations.dir_init} initialized in {t_elapse} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937acf95-47c5-42d2-bec4-1960ca8bb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies.attribute_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8763ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the strategy codes you wish to run in ssp\n",
    "strategies_to_run = [0, 6003, 6004, 6005]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960373ce-9c92-4998-87e1-79563b4b7800",
   "metadata": {},
   "source": [
    "##  Build our templates\n",
    "- let's use the default variable groupings for LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46000c-f47a-4fcd-ae46-44bf7fab2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building excel templates, make sure to include the strategies ids in the strategies attribute as well as the baseline (0)\n",
    "df_vargroups = _EXAMPLES(\"variable_trajectory_group_specification\")\n",
    "\n",
    "strategies.build_strategies_to_templates(\n",
    "    # df_trajgroup = df_vargroups,\n",
    "    # include_simplex_group_as_trajgroup = True,\n",
    "    strategies = strategies_to_run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec04da7-dd23-437c-bcc2-fd63541c44f5",
   "metadata": {},
   "source": [
    "# Finally, load SISEPUEDE so that we can run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d1cae-41a3-4344-b0ff-db9d8d41a619",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sisepuede as si\n",
    "# timestamp_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "ssp = si.SISEPUEDE(\n",
    "    \"calibrated\",\n",
    "    db_type = \"csv\",\n",
    "    #id_str = f\"sisepuede_run_2025-07-28T12:30:52.790396\",\n",
    "    initialize_as_dummy = not(energy_model_flag), # no connection to Julia is initialized if set to True\n",
    "    regions = [country_name],\n",
    "    strategies = strategies,\n",
    "    # try_exogenous_xl_types_in_variable_specification = True,\n",
    "    attribute_time_period = _ATTRIBUTE_TABLE_TIME_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24634e-19a9-457f-909f-be5696f1ed14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This runs the model, make sure you edit key_stretegy with the strategy ids you want to execute include baseline (0)\n",
    "dict_scens = {\n",
    "    ssp.key_design: [0],\n",
    "    ssp.key_future: [0],\n",
    "    ssp.key_strategy: strategies_to_run,\n",
    "}\n",
    "\n",
    "ssp.project_scenarios(\n",
    "    dict_scens,\n",
    "    save_inputs = True,\n",
    "    include_electricity_in_energy =energy_model_flag,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d2ecf",
   "metadata": {},
   "source": [
    "# Levers Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32468ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sisepuede.visualization.tables as svt\n",
    "tableau_levers_table = svt.LeversImplementationTable(strategies, )\n",
    "tableau_levers_table_csv = tableau_levers_table.build_table_for_strategies(\n",
    "    [6003, 6004, 6005]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fde668",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_levers_table_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f54b8-82f4-47e0-99a0-47b894039ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input and output files\n",
    "df_out = ssp.read_output(None)\n",
    "df_in = ssp.read_input(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[df_out.primary_id==0][[col for col in df_out.columns if col.startswith(\"prod_ippu_\")]].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb357b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[df_out.primary_id==0][[col for col in df_out.columns if col.startswith(\"prod_ippu_\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_ippu =matt.get_variable(\"Energy Demand by Fuel in SCOE\")\n",
    "demand_ippu.get_from_dataframe(df_out).iloc[35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4354dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_ippu =matt.get_variable(\"Energy Demand by Fuel in SCOE\")\n",
    "demand_ippu.get_from_dataframe(df_out).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_ippu =matt.get_variable(\"Energy Demand by Fuel in SCOE\")\n",
    "demand_ippu.get_from_dataframe(df_out).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_demand_electricity_scoe = matt.get_variable(\"SCOE Heat Energy Demand Scalar\")\n",
    "frac_demand_electricity_scoe.get_from_dataframe(df_in).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918158d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_demand_electricity_scoe = matt.get_variable(\"SCOE Initial Per GDP Heat Energy Consumption\")\n",
    "frac_demand_electricity_scoe.get_from_dataframe(df_in).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_demand_electricity_scoe = matt.get_variable(\"SCOE Initial Per GDP Electric Appliances Energy Consumption\")\n",
    "frac_demand_electricity_scoe.get_from_dataframe(df_in).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8aa409",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_demand_electricity_scoe = matt.get_variable(\"SCOE Initial Per Household Electric Appliances Energy Consumption\")\n",
    "frac_demand_electricity_scoe.get_from_dataframe(df_in).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4380720",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_energy_tech = matt.get_variable(\"Energy Demand by Fuel in Energy Technology\")\n",
    "demand_ccsq = matt.get_variable(\"Energy Demand by Fuel in CCSQ\")\n",
    "demand_industrial_energy = matt.get_variable(\"Energy Demand by Fuel in Industrial Energy\")\n",
    "demand_scoe = matt.get_variable(\"Energy Demand by Fuel in SCOE\")\n",
    "demand_transportation = matt.get_variable(\"Energy Demand by Fuel in Transportation\")\n",
    "demand_industrial = matt.get_variable(\"Energy Demand in Industrial Energy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_scoe.get_from_dataframe(df_out).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a559a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_field_stack(\n",
    "    df,\n",
    "    fields,\n",
    "    dict_format,\n",
    "    time_col=\"time_period\",\n",
    "    primary_id=0,\n",
    "    figsize=(18, 8),\n",
    "    legend_loc='upper right',\n",
    "    legend_bbox=(1.1, 1),\n",
    "    ylabel=\"MT Emissions CO2e\",\n",
    "    xlabel=\"Time Period\",\n",
    "    title=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a stack plot of the selected fields for a given primary_id.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing output data.\n",
    "        fields (list): List of column names to plot.\n",
    "        dict_format (dict): Formatting dictionary for colors.\n",
    "        time_col (str): Name of the time column.\n",
    "        primary_id (int): Value of primary_id to filter.\n",
    "        figsize (tuple): Figure size.\n",
    "        legend_loc (str): Legend location.\n",
    "        legend_bbox (tuple): Legend bbox_to_anchor.\n",
    "        ylabel (str): Y-axis label.\n",
    "        xlabel (str): X-axis label.\n",
    "        title (str): Plot title.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    df_plot = df[df[ssp.key_primary].isin([primary_id])]\n",
    "\n",
    "    fig, ax = spu.plot_stack(\n",
    "        df_plot,\n",
    "        fields,\n",
    "        dict_formatting=dict_format,\n",
    "        field_x=time_col,\n",
    "        figtuple=(fig, ax),\n",
    "    )\n",
    "\n",
    "    ax.legend(loc=legend_loc, bbox_to_anchor=legend_bbox, title=\"Fields\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f46b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix FGTV when having super large spikes (Only use when there are spikes)\n",
    "primary_id_to_fix = 72072\n",
    "df_out[df_out.primary_id==primary_id_to_fix][[col for col in df_out.columns if 'fgtv' in col]].plot(figsize=(10,5))\n",
    "\n",
    "def hampel_clean(\n",
    "    s: pd.Series,\n",
    "    window: int = 7,\n",
    "    n_sigmas: float = 5.0,\n",
    "    strategy: str = \"prev\",  # \"prev\" | \"median\" | \"linear\" | \"nan\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects spikes using a rolling median + MAD (Hampel) and replaces them.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cleaned : pd.Series\n",
    "    mask : pd.Series[bool]  # True where a spike was found\n",
    "    \"\"\"\n",
    "    s = s.astype(float).copy()\n",
    "\n",
    "    # Rolling median\n",
    "    med = s.rolling(window, center=True, min_periods=max(3, window//2)).median()\n",
    "\n",
    "    # Rolling MAD (median absolute deviation)\n",
    "    def _mad(x):\n",
    "        m = np.median(x)\n",
    "        return np.median(np.abs(x - m))\n",
    "    mad = s.rolling(window, center=True, min_periods=max(3, window//2)).apply(_mad, raw=False)\n",
    "\n",
    "    # Robust z-score using MAD (~= std when multiplied by 1.4826)\n",
    "    sigma = 1.4826 * mad\n",
    "    # Fallbacks at edges\n",
    "    med = med.fillna(s.median())\n",
    "    sigma = sigma.replace(0, np.nan).fillna(sigma[sigma>0].median() or 1.0)\n",
    "\n",
    "    z = (s - med).abs() / sigma\n",
    "    mask = z > n_sigmas  # spike locations (True = spike)\n",
    "\n",
    "    # Impute\n",
    "    cleaned = s.copy()\n",
    "    if strategy == \"prev\":\n",
    "        # copy previous *valid* value\n",
    "        # (for first element or consecutive spikes, fall back to local median)\n",
    "        for idx in np.where(mask)[0]:\n",
    "            if idx > 0 and not np.isnan(cleaned.iloc[idx-1]):\n",
    "                cleaned.iloc[idx] = cleaned.iloc[idx-1]\n",
    "            else:\n",
    "                cleaned.iloc[idx] = med.iloc[idx]\n",
    "    elif strategy == \"median\":\n",
    "        cleaned[mask] = med[mask]\n",
    "    elif strategy == \"linear\":\n",
    "        tmp = cleaned.copy()\n",
    "        tmp[mask] = np.nan\n",
    "        cleaned = tmp.interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    elif strategy == \"nan\":\n",
    "        cleaned[mask] = np.nan\n",
    "    else:\n",
    "        raise ValueError(\"Unknown strategy\")\n",
    "\n",
    "    return cleaned, mask\n",
    "\n",
    "# --- Example on your Series s ---\n",
    "# s_clean, spike_mask = hampel_clean(s, window=7, n_sigmas=5.0, strategy=\"prev\")\n",
    "\n",
    "# select the subset\n",
    "subset = df_out[df_out.primary_id == primary_id_to_fix].copy()\n",
    "\n",
    "# get only the relevant columns\n",
    "cols = [c for c in df_out.columns if 'fgtv' in c]\n",
    "\n",
    "# make a copy to store cleaned results\n",
    "cleaned_subset = subset.copy()\n",
    "spike_masks = {}\n",
    "\n",
    "# apply Hampel cleaning to each relevant column\n",
    "for c in cols:\n",
    "    cleaned_subset[c], spike_masks[c] = hampel_clean(\n",
    "        subset[c],\n",
    "        window=7,\n",
    "        n_sigmas=5.0,\n",
    "        strategy=\"prev\"  # or \"median\"/\"linear\"\n",
    "    )\n",
    "\n",
    "# if you want to merge back into df_out:\n",
    "df_out.loc[df_out.primary_id == primary_id_to_fix, cols] = cleaned_subset[cols]\n",
    "df_out[df_out.primary_id==primary_id_to_fix][[col for col in df_out.columns if 'fgtv' in col]].plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184008da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fields to plot and the formatting dictionary\n",
    "subsector_emission_fields = matt.get_all_subsector_emission_total_fields()\n",
    "\n",
    "dict_format = dict(\n",
    "    (k, {\"color\": v}) for (k, v) in\n",
    "    matt.get_subsector_color_map().items()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7263eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_ids_to_plot = df_out[ssp.key_primary].unique()\n",
    "primary_ids_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "for primary_id in primary_ids_to_plot:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_out,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=primary_id,\n",
    "        title=f\"Emissions Stack Plot for Primary ID {primary_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[df_out.primary_id==0][[col for col in df_out.columns if col.startswith(\"prod_ippu_metals_tonne\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf46be0-6ab4-4731-b922-eb21eeefef7b",
   "metadata": {},
   "source": [
    "# Export Wide File (Last Mandatory Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac388d-9ff2-45fc-a49a-ad5af38a0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_primaries = sorted(list(df_out[ssp.key_primary].unique()))\n",
    "\n",
    "# build if unable to simply read the data frame\n",
    "if df_in is None:\n",
    "    df_in = []\n",
    "     \n",
    "    for region in ssp.regions:\n",
    "        for primary in all_primaries: \n",
    "            df_in_filt = ssp.generate_scenario_database_from_primary_key(primary)\n",
    "            df_in.append(df_in_filt.get(region))\n",
    "    \n",
    "    df_in = pd.concat(df_in, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_export = pd.merge(\n",
    "    df_out,\n",
    "    df_in,\n",
    "    how = \"left\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# check output directory \n",
    "dir_pkg = os.path.join(\n",
    "    ssp.file_struct.dir_out, \n",
    "    f\"sisepuede_summary_results_run_{ssp.id_fs_safe}\"\n",
    ")\n",
    "os.makedirs(dir_pkg) if not os.path.exists(dir_pkg) else None\n",
    "\n",
    "\n",
    "for tab in [\"ATTRIBUTE_STRATEGY\"]:\n",
    "    table_df = ssp.database.db.read_table(tab)\n",
    "    if table_df is not None:\n",
    "        table_df.to_csv(\n",
    "            os.path.join(dir_pkg, f\"{tab}.csv\"),\n",
    "            index=None,\n",
    "            encoding=\"UTF-8\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: Table {tab} returned None.\")\n",
    "\n",
    "\n",
    "df_primary = (\n",
    "    ssp\n",
    "    .odpt_primary\n",
    "    .get_indexing_dataframe(\n",
    "        sorted(list(df_out[ssp.key_primary].unique()))\n",
    "    )\n",
    ")\n",
    "    \n",
    "df_primary.to_csv(\n",
    "    os.path.join(dir_pkg, f\"ATTRIBUTE_PRIMARY.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")\n",
    "\n",
    "df_export.to_csv(\n",
    "    os.path.join(dir_pkg, f\"sisepuede_results_{ssp.id_fs_safe}_WIDE_INPUTS_OUTPUTS.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc34b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the directory where the outputs are stored\n",
    "ssp.file_struct.dir_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3626cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID_OUTPUT_DIR_PATH = os.path.join(\n",
    "    RUN_OUTPUT_DIR_PATH, \n",
    "    f\"sisepuede_results_{ssp.id_fs_safe}\"\n",
    ")\n",
    "\n",
    "os.makedirs(RUN_ID_OUTPUT_DIR_PATH, exist_ok=True)\n",
    "\n",
    "df_primary.to_csv(\n",
    "    os.path.join(RUN_ID_OUTPUT_DIR_PATH, \"ATTRIBUTE_PRIMARY.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")\n",
    "\n",
    "df_export.to_csv(\n",
    "    os.path.join(RUN_ID_OUTPUT_DIR_PATH, f\"sisepuede_results_{ssp.id_fs_safe}_WIDE_INPUTS_OUTPUTS.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")\n",
    "\n",
    "for tab in [\"ATTRIBUTE_STRATEGY\"]:\n",
    "    table_df = ssp.database.db.read_table(tab)\n",
    "    if table_df is not None:\n",
    "        table_df.to_csv(\n",
    "            os.path.join(RUN_ID_OUTPUT_DIR_PATH, f\"{tab}.csv\"),\n",
    "            index=None,\n",
    "            encoding=\"UTF-8\"\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(f\"Warning: Table {tab} returned None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4077c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_levers_table_csv.to_csv(\n",
    "            os.path.join(RUN_ID_OUTPUT_DIR_PATH, \"tableau_levers_table.csv\"),\n",
    "            index=None,\n",
    "            encoding=\"UTF-8\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6dea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID_OUTPUT_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a324a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdp_df = df_in[[\"time_period\", \"gdp_mmm_usd\"]].copy()\n",
    "# gdp_df[\"year\"] = gdp_df[\"time_period\"] + 2015\n",
    "# gdp_df = gdp_df.drop(columns=[\"time_period\"])\n",
    "# gdp_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssp_mexico_nm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
